{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIiRdNK5mVzC"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyPoaLbngKpN"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zhDh7AZjo1J"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IVb76jTrjfF2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling ,TextDataset\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ln3RHzznBZWq"
      },
      "outputs": [],
      "source": [
        "import json \n",
        "train_set = []\n",
        "valid_set = []\n",
        "data = json.load(open(\"./dataset.json\", \"r\"))\n",
        "for idx, row in enumerate(data):\n",
        "    if idx % 2 != 0:\n",
        "        train_set.append(row)\n",
        "        continue \n",
        "    row = row.split(\" . \")\n",
        "    train_set.append(\" . \".join(row[:-1]))\n",
        "    valid_set.append(row[-1])\n",
        "with open(\"./train.json\", \"w\") as f:\n",
        "    json.dump(train_set, f)\n",
        "    f.close()\n",
        "with open(\"./valid.json\", \"w\") as f:\n",
        "    json.dump(valid_set, f)\n",
        "    f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbY8HWbfjnot"
      },
      "outputs": [],
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2-medium\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2-medium\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3Hybbt67cx8e"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"h.23\" in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwaZBWuCeUvP"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57BCWka0glK0",
        "outputId": "888e36d6-0a01-4b08-f5ed-beda7dd64640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0115,  0.0031, -0.0073,  ..., -0.0526, -0.1757,  0.0257],\n",
            "        [-0.0086,  0.0636, -0.0182,  ..., -0.0136, -0.1215,  0.0535],\n",
            "        [ 0.0585,  0.0689,  0.0262,  ..., -0.1006, -0.1979, -0.0039],\n",
            "        ...,\n",
            "        [ 0.0016, -0.0441, -0.0517,  ..., -0.1008, -0.0087,  0.0264],\n",
            "        [-0.1437, -0.0463, -0.0065,  ...,  0.0746, -0.0472, -0.0383],\n",
            "        [ 0.0207, -0.0133, -0.0259,  ...,  0.0389, -0.0023,  0.0011]],\n",
            "       requires_grad=True) True\n"
          ]
        }
      ],
      "source": [
        "for param in model.lm_head.parameters():\n",
        "    param.requires_grad = True\n",
        "    print(param, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-z-lluZj9R1",
        "outputId": "d9fb5eb5-5e04-4537-c0ba-a91f8ab7086c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='./train.json',\n",
        "    block_size=50\n",
        ")\n",
        "valid_dataset = TextDataset(\n",
        "    tokenizer=tokenizer, \n",
        "    file_path=\"./valid.json\", \n",
        "    block_size=50\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "34Hj_kghfShD"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    global tokenizer\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    bleu = evaluate.load(\"bleu\")\n",
        "    results = bleu.compute(predictions=preds, references=labels)\n",
        "    return {\n",
        "        \"bleu\": results[\"bleu\"],\n",
        "        # \"bleu\": 1.0,\n",
        "        \"brevity_penalty\": results[\"brevity_penalty\"],\n",
        "        \"length_ratio\": results[\"length_ratio\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "niTcdcO2kXIr"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./checkpoint\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=20,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy =\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=3e-4,\n",
        "    save_total_limit=1,\n",
        "    warmup_steps=2000,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type='linear',\n",
        "    # max_steps=4\n",
        ")\n",
        "\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "trainer = Trainer(\n",
        "    model=model.to(\"cuda\"),\n",
        "    compute_metrics=compute_metrics,              \n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=valid_dataset,\n",
        "    data_collator=collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "9oT5cbHjmE0R",
        "outputId": "1fd7687d-e994-452d-b656-bd1ba4f8153e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='290' max='4020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 290/4020 02:40 < 34:37, 1.80 it/s, Epoch 1.44/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Bleu</th>\n",
              "      <th>Brevity Penalty</th>\n",
              "      <th>Length Ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.775500</td>\n",
              "      <td>3.689424</td>\n",
              "      <td>0.099489</td>\n",
              "      <td>0.969381</td>\n",
              "      <td>0.969840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23GiX2jwmIk8"
      },
      "outputs": [],
      "source": [
        "!mkdir ./model_weight_v1 && mkdir ./tokenizer_weight_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iwKexdDmoH4"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"./model_weight_v1\")\n",
        "tokenizer.save_pretrained(\"./tokenizer_weight_v1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6p6G5AhmtCZ"
      },
      "outputs": [],
      "source": [
        "!mv ./model_weight_v1 ./drive/MyDrive/checkpoint_gpt && mv ./tokenizer_weight_v1 ./drive/MyDrive/checkpoint_gpt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef0Xt8YOmb-x"
      },
      "source": [
        "# **Inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwMR9SFime1n"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "\n",
        "GENERATOR = pipeline('text-generation', model='./model/', tokenizer=\"./tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2lqEVhdoDca"
      },
      "outputs": [],
      "source": [
        "output = GENERATOR(txt, max_length=50, num_return_sequences=3, num_beams=3, no_repeat_ngram_size=2, early_stopping=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
